<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Educate-R - R</title>
		<description>Posts categorized as 'R'</description>
		<link>http://educate-r.org</link>
		<atom:link href="http://educate-r.org/feed.category.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Remove leading 0 with ggplot2.</title>
				<description>&lt;p&gt;I recently had an occasion while working on a three variable interaction plot for a paper where I wanted to remove the leading 0&#39;s in the x-axis text labels using &lt;em&gt;ggplot2&lt;/em&gt;. This was primarily due to some space concerns I had for the x-axis labels. Unfortunately, I did not find an obvious way to do this in my first go around. After tickering a bit, I&#39;ve found a workaround. The process is walked through below.&lt;/p&gt;

&lt;p&gt;First, some simulated data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# Sim some data
simdata &amp;lt;- data.frame(x = runif(2400, min = .032, max = .210),
                      y = c(rnorm(2000, mean = 0, sd = .1), 
                            rnorm(400, mean = 1, sd = .25)),
                      group = c(sample(1:2, 1600, replace = TRUE),
                                rep(1, 400), 
                                rep(2, 400)),
                      facet = rep(1:3, each = 800))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As shown below, initially there is no group differences, but there are facet differences. Exploring the interaction between the grouping variables shows there is a two variable interaction. Note: This example is not identical to the three variable interaction I originally described above, but assume here that the x variable is also important.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;with(simdata, tapply(y, group, mean))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##          1          2 
## 0.00342121 0.33040069
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;with(simdata, tapply(y, facet, mean))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##             1             2             3 
## -0.0009751953  0.0025336609  0.5028529069
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;with(simdata, tapply(y, interaction(group, facet), mean))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##           1.1           2.1           1.2           2.2           1.3 
##  0.0031464214 -0.0048761903  0.0056148873 -0.0005785326  0.0014837970 
##           2.3 
##  1.0042220169
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the example in the paper, I aggregated the unique x values to the third decimal place. That is done with the following &lt;em&gt;dplyr&lt;/em&gt; code. Note: The data did not need to be aggregated, but it is a bit easier to work with when plotting later.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# round value to .001 and aggregate
simdata$x_rd &amp;lt;- round(simdata$x, 3)

# aggregate
library(dplyr)
simdata_agg &amp;lt;- simdata %&amp;gt;%
  group_by(x_rd, group, facet) %&amp;gt;%
  summarise(y = mean(y))
simdata_agg 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [962 x 4]
## Groups: x_rd, group
## 
##     x_rd group facet            y
## 1  0.032     1     2 -0.088397852
## 2  0.032     2     2  0.228654211
## 3  0.033     1     1 -0.001843538
## 4  0.033     1     2 -0.021662299
## 5  0.033     1     3 -0.110077646
## 6  0.033     2     1  0.080429131
## 7  0.033     2     3  0.915228939
## 8  0.034     1     1  0.025164086
## 9  0.034     1     2 -0.046522430
## 10 0.034     1     3  0.037889712
## ..   ...   ...   ...          ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that the data is aggregated, it can be directly plotted with &lt;em&gt;ggplot2&lt;/em&gt;. This is the base plot that contains the leading 0&#39;s by default and treats the x variable as continuous (which it really is continuous).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(ggplot2)
p &amp;lt;- ggplot(simdata_agg, aes(x = x_rd, y = y, shape = factor(group))) + 
  theme_bw()
p + geom_point(size = 3) + facet_grid(. ~ facet) + 
  scale_x_continuous(&quot;x&quot;, limits = c(0, .25), 
                     breaks = seq(0, .25, .05))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/plotwith0-1.png&quot; alt=&quot;&quot; /&gt;
The plot above is a good start, but I was worried about the x-axis labels being too close together and ultimately being difficult to read. I decided I wanted to omit the leading 0&#39;s to omit some space. This was useful in my scenario as the variable on the x-axis could only take on values between 0 and 1, therefore the leading 0 is not important.&lt;/p&gt;

&lt;p&gt;One way to remove the leading 0 is to convert the continuous variable into a character variable and use a simple regular expression (with &lt;em&gt;gsub&lt;/em&gt;) to remove the 0 at the beginning of the character string. Below is the code to do that and also the resulting plot. The key point of the plotting code below is the use of the &lt;em&gt;breaks&lt;/em&gt; argument to &lt;em&gt;scale_x_discrete&lt;/em&gt;. Without this all the unique character values will be plotted, not good.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;simdata_agg$x_char &amp;lt;- as.character(simdata_agg$x_rd)
simdata_agg$x_char &amp;lt;- gsub(&quot;^0&quot;, &quot;&quot;, simdata_agg$x_char)
p &amp;lt;- ggplot(simdata_agg, aes(x = x_char, y = y, shape = factor(group))) + 
  theme_bw()
p + geom_point(size = 3) + facet_grid(. ~ facet) + 
  scale_x_discrete(&quot;x&quot;, breaks = c(&#39;.00&#39;, &#39;.05&#39;, &#39;.1&#39;, &#39;.15&#39;, &#39;.2&#39;, &#39;.25&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/plotno0-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The plot above has a few flaws. First, there are values at the edge of each facet. This could be fixed with the &lt;em&gt;expand&lt;/em&gt; argument to &lt;em&gt;scale_x_discrete&lt;/em&gt;, but I still wanted to include the value of .00 on the x-axis. Secondly, the x-axis text labels are not uniformly formatted which is not ideal (e.g. .1 should be .10).&lt;/p&gt;

&lt;p&gt;To fix this, some made up data needs to be added to the data frame. Some care needs to be done here as well as a value of .00 can not just be added to the x variable plotted. This would place a non-uniform gap between .00 and .05 (not shown, but try it for yourself by adapting the code below). Therefore, all values between 0 and .031 need to be manually added to the data frame to keep the spacing uniform. Finally, to not plot the made up values, I created a transparency variable called alpha. This variable was used to set the alpha values to 0 for the made up values and 1 for the real values. &lt;em&gt;scale_alpha_discrete&lt;/em&gt; was used to specify the range of alpha values, this is important otherwise the made up numbers will show up as a light gray. The final code to manually add the new data is shown below. Anyone have a less workaround procedure?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# Reset aggregation vector
simdata_agg &amp;lt;- simdata %&amp;gt;%
  group_by(x_rd, group, facet) %&amp;gt;%
  summarise(y = mean(y))

# Add values
simdata_agg &amp;lt;- rbind(data.frame(x_rd = seq(0, .031, .001),
                                group = rep(1, 32),
                                facet = rep(1, 32),
                                y = rep(0, 32)),
                     simdata_agg)

# Create a new variable to use for transparent points
simdata_agg$alpha &amp;lt;- ifelse(simdata_agg$x_rd &amp;lt; .032, 0, 1)

# Create x_char variable again
simdata_agg$x_char &amp;lt;- as.character(simdata_agg$x_rd)
simdata_agg$x_char &amp;lt;- gsub(&quot;^0&quot;, &quot;&quot;, simdata_agg$x_char)

# Needed formatting
simdata_agg$x_char &amp;lt;- ifelse(simdata_agg$x_char == &#39;&#39;, &#39;.00&#39;,
                             simdata_agg$x_char)
simdata_agg$x_char &amp;lt;- ifelse(simdata_agg$x_char == &#39;.2&#39;, &#39;.20&#39;,
                             simdata_agg$x_char)
simdata_agg$x_char &amp;lt;- ifelse(simdata_agg$x_char == &#39;.1&#39;, &#39;.10&#39;,
                             simdata_agg$x_char)

# Final plot
p &amp;lt;- ggplot(simdata_agg, aes(x = x_char, y = y, shape = factor(group))) + 
  theme_bw()
p + geom_point(aes(alpha = factor(alpha)), size = 3) + 
  facet_grid(. ~ facet) + 
  scale_x_discrete(&quot;x&quot;, breaks = c(&#39;.00&#39;, &#39;.05&#39;, &#39;.10&#39;, &#39;.15&#39;, &#39;.20&#39;),
                   expand = c(.05, .05)) + 
  scale_alpha_discrete(guide = FALSE, range = c(0, 1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/addmadeupvalues-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
				<pubDate>Mon, 23 Mar 2015 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2015/03/23/removelead0/</link>
				<guid isPermaLink="true">http://educate-r.org//2015/03/23/removelead0/</guid>
			</item>
		
			<item>
				<title>Structured simulation of regression models - simReg package.</title>
				<description>&lt;p&gt;I&#39;d like to introduce a package that simulates regression models. This includes both single level and multilevel (i.e. hierarchical or linear mixed) models up to two levels of nesting. The package produces a unified framework to simulate all types of continuous regression models. In the future, I&#39;d like to add the ability to simulate generalized linear models. This package is an extension of the functions I used to simulate data for my dissertation.&lt;/p&gt;

&lt;p&gt;The package is currently on github &lt;a href=&quot;https://github.com/lebebr01/simReg&quot;&gt;https://github.com/lebebr01/simReg&lt;/a&gt;. Therefore, you can currently install the package by using the &lt;em&gt;devtools&lt;/em&gt; package like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(devtools)
install_github(&quot;lebebr01/simReg&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The primary function of interest in this package is &lt;em&gt;sim.reg&lt;/em&gt;. To show the use of this function, here is a simple example simulating a single level regression mode. Note, this example is pulled directly from the &lt;strong&gt;Intro&lt;/strong&gt; vignette.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(simReg)
set.seed(100)
fixed &amp;lt;- ~ 1 + act + diff + numCourse + act:numCourse
fixed.param &amp;lt;- c(2, 4, 1, 3.5, 2)
cov.param &amp;lt;- list(mean = c(0, 0, 0), sd = c(4, 3, 3), var.type = c(&quot;single&quot;, &quot;single&quot;, &quot;single&quot;))
n &amp;lt;- 150
errorVar &amp;lt;- 3
err.dist &amp;lt;- &quot;norm&quot;
temp.single &amp;lt;- sim.reg(fixed = fixed, fixed.param = fixed.param, cov.param = cov.param,
n = n, errorVar = errorVar, err.dist = err.dist, data.str = &quot;single&quot;)
head(temp.single)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept.     act     diff numCourse act.numCourse    Fbeta      err
## 1            1 -2.0088  3.10406    -5.566       11.1815 -0.05022 -3.35921
## 2            1  0.5261  4.96051    -3.056       -1.6077 -4.84527 -5.75176
## 3            1 -0.3157 -0.05384    -3.135        0.9897 -8.31073  1.63173
## 4            1  3.5471 -0.07261    -1.954       -6.9306 -4.58382  0.06435
## 5            1  0.4679  0.75074     1.148        0.5372  9.71476 -0.44783
## 6            1  1.2745 -1.01137     3.096        3.9455 24.81272  0.59651
##   sim.data ID
## 1   -3.409  1
## 2  -10.597  2
## 3   -6.679  3
## 4   -4.519  4
## 5    9.267  5
## 6   25.409  6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see from the above code, the package uses a single sided equation to represent the fixed effects. Other arguments include the values for those fixed effects (fixed.param), the scale for the covariates (cov.param), the sample size (n), the error variance (errorVar), and the error distribution (err.dist). These are all put into the function &lt;em&gt;sim.reg&lt;/em&gt; with the additional argument &lt;em&gt;data.str&lt;/em&gt; to tell the function that we indeed want a single level regression and you get the following output. The data frame that is returned gives the values for the design matrix, the fixed portion of the model (Fbeta), and the random error term (err). The value of most interest if conducting a simulation would be the actually simulated value (sim.data).&lt;/p&gt;

&lt;h3&gt;Nested Example&lt;/h3&gt;

&lt;p&gt;A slightly more complicated example is shown below where longitudinal data are simulated.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;fixed &amp;lt;- ~1 + time + diff + act + time:act
random &amp;lt;- ~1 + time + diff
fixed.param &amp;lt;- c(4, 2, 6, 2.3, 7)
random.param &amp;lt;- c(7, 4, 2)
cov.param &amp;lt;- list(mean = c(0, 0), sd = c(1.5, 4), var.type = c(&quot;lvl1&quot;, &quot;lvl2&quot;))
n &amp;lt;- 150
p &amp;lt;- 30
errorVar &amp;lt;- 4
randCor &amp;lt;- 0
rand.dist &amp;lt;- &quot;norm&quot;
err.dist &amp;lt;- &quot;norm&quot;
serCor &amp;lt;- &quot;ID&quot;
serCorVal &amp;lt;- NULL
data.str &amp;lt;- &quot;long&quot;
temp.long &amp;lt;- sim.reg(fixed, random, fixed.param, random.param, cov.param,
n, p, errorVar, randCor, rand.dist, err.dist, serCor, serCorVal, data.str)
head(temp.long)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept. time     diff    act time.act    b0      b1    b2   Fbeta
## 1            1    0 -0.05455  1.608    0.000 5.118 -0.1118 0.251   7.371
## 2            1    1 -2.23677 -1.349   -1.349 5.118 -0.1118 0.251 -19.968
## 3            1    2  0.50321 -6.028  -12.056 5.118 -0.1118 0.251 -87.237
## 4            1    3  1.25027  8.436   25.308 5.118 -0.1118 0.251 214.063
## 5            1    4  2.05871  3.917   15.667 5.118 -0.1118 0.251 143.031
## 6            1    5 -1.87968  7.598   37.990 5.118 -0.1118 0.251 286.125
##   randEff     err sim.data withinID clustID
## 1   5.104  3.2637    15.74        1       1
## 2   4.444  0.9355   -14.59        2       1
## 3   5.020 -3.1693   -85.39        3       1
## 4   5.096  4.1523   223.31        4       1
## 5   5.187 -3.1716   145.05        5       1
## 6   4.086 -0.2605   289.95        6       1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Most of the arguments should look familiar to above, but a few are new. Most notably these are a one sided equation for the random effects (random), their variances (random.param), the number of observations within a cluster (p), the correlation among the random effects (randCor), the simulated distribution of the random effects (rand.dist), the serial correlation model for within cluster residuals (serCor), the values for the serial correlation models (serCorVal). Note now since this represents longitudinal data, the &lt;em&gt;data.str&lt;/em&gt; argument is now specified as &#39;long&#39;.&lt;/p&gt;

&lt;h3&gt;Other features&lt;/h3&gt;

&lt;p&gt;The package also simulates cross sectional multilevel models, covariates that are either a factor, ordinal, or categorical, and the basics for power simulation are there.&lt;/p&gt;

&lt;p&gt;For further information, see the vignette by doing the following after installing the package:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;vignette(&quot;Intro&quot;, package = &quot;simReg&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bugs, comments, or feature requests can be submitted on the github site &lt;a href=&quot;https://github.com/lebebr01/simReg/issues&quot;&gt;https://github.com/lebebr01/simReg/issues&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Wed, 01 Oct 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/10/01/simReg/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/10/01/simReg/</guid>
			</item>
		
			<item>
				<title>Google location data -- Where I've been.</title>
				<description>&lt;p&gt;I was emailed by a friend that was looking into their google location data and had asked if I had ever used a json file before in R. I said I had not, but I knew there were packages to do such things. The things I sent were things he had already tried, so what did I decide to do? I went ahead and downloaded my own google location data.&lt;/p&gt;

&lt;p&gt;If you use google services (particularly have an android phone) you can get your google location information here buried in google&#39;s settings page: &lt;a href=&quot;https://www.google.com/settings/datatools&quot;&gt;Google Data Page&lt;/a&gt;. From there you can click on create new archive at the bottom of the rightmost column under &quot;Download your data&quot;. If you&#39;d like to replicate the map below, you just need the location data, therefore I unselected all of the options except for location. Then there is some thinking on google&#39;s servers and they give you a download file (either .zip, .tbz, or .tgz) from which you can download. Mine did not take long to prepare, if they have more location information on you it may take longer.&lt;/p&gt;

&lt;p&gt;Below is a map of all the locations I&#39;ve been. I rounded the latitude and longitude values to two decimals (and had to add the decimals) to create less exact location values. This step could obviously be omitted. You&#39;ll notice in the ggplot2 code that I set the alpha equal to .01, this allowed the locations where I&#39;ve been longer to be darker. You could get more fancy with this, especially if you are able to figure out the code google uses for their timestamp. Just looked like mumbo jumbo to me. There is also accuracy, velocity, heading, altitude, and activity data.&lt;/p&gt;

&lt;p&gt;Kind of a cool process. The map shows places I&#39;ve been the last year or so (does not include San Francisco from AERA two years ago) including living in Fayetteville, Iowa City, Saint Paul. It also shows a few places I was for interviews last year including travel through some airports (Dallas, Houston, Charlotte, Chicago) and even shows my honeymoon to the panhandle of Florida. It also made me realize how much more I need to explore to the west (and east to some extent).&lt;/p&gt;

&lt;p&gt;Below is the code I used to load, manipulate, and plot my google location data. To replicate you would need to download your own google location data. Has anyone else made sense of all this data?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/myjson.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rjson)
json_file &amp;lt;- &quot;path/to/your/json/file&quot;
json_data &amp;lt;- fromJSON(file = json_file)
latlong &amp;lt;- data.frame(do.call(&quot;rbind&quot;, json_data[[2]]))
latlong2 &amp;lt;- subset(latlong, select = c(latitudeE7, longitudeE7))
latlong2$latR &amp;lt;- as.numeric(paste0(substr(as.character(latlong2$latitudeE7), 1, 2), 
                                   &quot;.&quot;, substr(as.character(latlong2$latitudeE7), 3, 4)))
latlong2$longR &amp;lt;- as.numeric(paste0(substr(as.character(latlong2$longitudeE7), 1, 3), 
                                    &quot;.&quot;, substr(as.character(latlong2$longitudeE7), 4, 5)))

library(maps)
library(ggplot2)

states &amp;lt;- map_data(&quot;state&quot;)

p &amp;lt;- ggplot(states) + 
  geom_polygon(aes(x = long, y = lat, group = group), 
               fill = &quot;white&quot;, color = &quot;black&quot;) + 
  theme_bw() + 
  theme(axis.text = element_blank(), line = element_blank(), 
        rect = element_blank(), axis.title = element_blank())
p + geom_point(data = latlong2, aes(x = longR, y = latR), 
               alpha = .01, color = &quot;red&quot;, size = 3)
&lt;/code&gt;&lt;/pre&gt;
</description>
				<pubDate>Fri, 26 Sep 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/09/26/googlelocations/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/09/26/googlelocations/</guid>
			</item>
		
			<item>
				<title>Offense or defense improve likelihood of becoming bowl eligible?</title>
				<description>&lt;p&gt;I saw a post recently about the likelihood of a baseball team winning based on how many runs, hits, and other baseball statistics. I liked the idea and thought of applying that to college football. Particularly, I&#39;m interested in knowing whether scoring more points or having a stout defense improves the likelihood of becoming bowl eligible.&lt;/p&gt;

&lt;p&gt;Using some data scraped from the &lt;a href=&quot;http://www.cfbdatawarehouse.com/&quot;&gt;cfbDatawarehouse&lt;/a&gt; to figure out how likely a team would be bowl eligible based on the number of points they score. Below are the results of my exploration looking at both the points scores metric and the points against metric (also there is a quick interactive rCharts version of the plot down further). Seems to me that scoring more points leads to more assured success in the college game, perhaps that is why offensive recruits seem to be more sought after. This would also be interesting to create by decade to see if trends have shifted over the years.&lt;/p&gt;

&lt;p&gt;Enjoy, plots (and code for plots) shown below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;p &amp;lt;- ggplot(coaches, aes(x = PF)) + theme_bw() 
p + stat_smooth(data = ovrBE, aes(x = avg, y = bpct, linetype = group), 
                se = FALSE, size = 1.5, method = &quot;loess&quot;) + 
  geom_point(data = ovrBE, aes(x=avg, y = bpct, color = group), size = 2) + 
  scale_x_continuous(&quot;Points&quot;, limits = c(0, 500), breaks = c(0, 100, 200, 300, 400, 500)) + 
  scale_color_brewer(palette = &quot;Dark2&quot;) + 
  ylab(&quot;Bowl Eligibility Likelihood&quot;) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/points.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rCharts)

h1 &amp;lt;- hPlot(x = &quot;avg&quot;, y = &quot;bpct&quot;, group = &quot;group&quot;, data = ovrBE)
h1$yAxis(title = list(text = &quot;Bowl Eligibility Likelihood&quot;), min = 0, max = 1, tickInterval = .1)
h1$xAxis(title = list(text = &quot;Points&quot;),
         min = 0, max = 500, tickInterval = 100)
h1$legend(verticalAlign = &quot;top&quot;, align = &quot;right&quot;, layout = &quot;vertical&quot;, title = list(text = &quot;Group&quot;))
h1$plotOptions(series = list(lineWidth = 2))
h1$print(&#39;chart1&#39;, include_assets = TRUE, cdn = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;script type=&#39;text/javascript&#39; src=//code.jquery.com/jquery-1.9.1.min.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=//code.highcharts.com/highcharts.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=//code.highcharts.com/highcharts-more.js&quot;&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=//code.highcharts.com/modules/exporting.js&gt;&lt;/script&gt;


&lt;p&gt;
 &lt;style&gt;
  .rChart {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
    height: 400px;
  }&lt;br/&gt;
  &lt;/style&gt;&lt;/p&gt;

&lt;div id = &#39;chart1&#39; class = &#39;rChart highcharts&#39;&gt;&lt;/div&gt;


&lt;script type=&#39;text/javascript&#39;&gt;
    (function($){
        $(function () {
            var chart = new Highcharts.Chart({
 &quot;dom&quot;: &quot;chart1&quot;,
&quot;width&quot;:            800,
&quot;height&quot;:            400,
&quot;credits&quot;: {
 &quot;href&quot;: null,
&quot;text&quot;: null 
},
&quot;exporting&quot;: {
 &quot;enabled&quot;: false 
},
&quot;title&quot;: {
 &quot;text&quot;: null 
},
&quot;yAxis&quot;: [
 {
 &quot;title&quot;: {
 &quot;text&quot;: &quot;Bowl Eligibility Likelihood&quot; 
},
&quot;min&quot;:              0,
&quot;max&quot;:              1,
&quot;tickInterval&quot;:            0.1 
} 
],
&quot;series&quot;: [
 {
 &quot;data&quot;: [
 [
           34.5,
         0.848 
],
[
           62.5,
         0.889 
],
[
           71.5,
          0.85 
],
[
           77.5,
         0.881 
],
[
             83,
         0.846 
],
[
             88,
         0.789 
],
[
             92,
         0.702 
],
[
             96,
         0.789 
],
[
           99.5,
         0.745 
],
[
          102.5,
         0.708 
],
[
            105,
         0.625 
],
[
            108,
         0.753 
],
[
          111.5,
         0.754 
],
[
          114.5,
         0.704 
],
[
            117,
         0.732 
],
[
          119.5,
         0.697 
],
[
            122,
         0.649 
],
[
            124,
         0.627 
],
[
          126.5,
         0.643 
],
[
            129,
         0.635 
],
[
            131,
         0.732 
],
[
          133.5,
         0.657 
],
[
            136,
         0.721 
],
[
            138,
         0.532 
],
[
            140,
         0.593 
],
[
            142,
         0.617 
],
[
            144,
         0.531 
],
[
            146,
         0.582 
],
[
          147.5,
         0.576 
],
[
            149,
         0.646 
],
[
            151,
         0.542 
],
[
            153,
         0.692 
],
[
            155,
         0.619 
],
[
            157,
         0.677 
],
[
            159,
         0.582 
],
[
          160.5,
         0.553 
],
[
            162,
         0.573 
],
[
            164,
         0.611 
],
[
          165.5,
         0.725 
],
[
            167,
         0.585 
],
[
            169,
         0.597 
],
[
          170.5,
         0.676 
],
[
            172,
           0.5 
],
[
          173.5,
         0.619 
],
[
            175,
         0.508 
],
[
            177,
         0.514 
],
[
            179,
         0.533 
],
[
            181,
         0.549 
],
[
          182.5,
         0.479 
],
[
            184,
         0.635 
],
[
          185.5,
         0.571 
],
[
            187,
         0.531 
],
[
          188.5,
         0.564 
],
[
            190,
         0.594 
],
[
            192,
         0.557 
],
[
          193.5,
         0.556 
],
[
            195,
         0.593 
],
[
          196.5,
         0.703 
],
[
            198,
         0.562 
],
[
          199.5,
         0.578 
],
[
            201,
         0.508 
],
[
            203,
         0.623 
],
[
            205,
         0.657 
],
[
            207,
         0.536 
],
[
          208.5,
         0.487 
],
[
          209.5,
          0.55 
],
[
            211,
         0.588 
],
[
          212.5,
          0.49 
],
[
          213.5,
         0.462 
],
[
            215,
         0.479 
],
[
            217,
         0.533 
],
[
            219,
         0.704 
],
[
          220.5,
         0.562 
],
[
            222,
         0.468 
],
[
            224,
         0.574 
],
[
          225.5,
         0.568 
],
[
          226.5,
          0.64 
],
[
            228,
         0.593 
],
[
          229.5,
         0.629 
],
[
            231,
         0.531 
],
[
            233,
         0.478 
],
[
            235,
         0.464 
],
[
          236.5,
         0.469 
],
[
            238,
         0.539 
],
[
            240,
         0.547 
],
[
          241.5,
         0.423 
],
[
            243,
         0.561 
],
[
          244.5,
         0.353 
],
[
            246,
         0.603 
],
[
            248,
         0.429 
],
[
            250,
          0.54 
],
[
            252,
         0.472 
],
[
            254,
         0.387 
],
[
            256,
         0.609 
],
[
          257.5,
         0.472 
],
[
            259,
         0.478 
],
[
            261,
         0.426 
],
[
            263,
         0.485 
],
[
            265,
          0.47 
],
[
          266.5,
         0.361 
],
[
            268,
         0.453 
],
[
          270.5,
         0.386 
],
[
            273,
         0.475 
],
[
            275,
         0.407 
],
[
          276.5,
         0.622 
],
[
            278,
           0.5 
],
[
            280,
         0.481 
],
[
            282,
         0.589 
],
[
          283.5,
         0.378 
],
[
            285,
         0.549 
],
[
            287,
          0.46 
],
[
            289,
         0.486 
],
[
            291,
         0.379 
],
[
          293.5,
          0.43 
],
[
          295.5,
         0.364 
],
[
            297,
         0.453 
],
[
          299.5,
         0.353 
],
[
            302,
         0.447 
],
[
          304.5,
         0.489 
],
[
            307,
         0.358 
],
[
          309.5,
           0.5 
],
[
            312,
         0.351 
],
[
          314.5,
         0.426 
],
[
          317.5,
           0.4 
],
[
            321,
           0.4 
],
[
          324.5,
         0.333 
],
[
          327.5,
         0.385 
],
[
          330.5,
         0.246 
],
[
            334,
         0.328 
],
[
          337.5,
         0.227 
],
[
          340.5,
         0.357 
],
[
          343.5,
         0.396 
],
[
            347,
         0.297 
],
[
            351,
         0.262 
],
[
            355,
          0.31 
],
[
            359,
         0.308 
],
[
            363,
         0.308 
],
[
            367,
         0.348 
],
[
          371.5,
         0.291 
],
[
          376.5,
         0.246 
],
[
            382,
         0.309 
],
[
          387.5,
         0.255 
],
[
            394,
         0.259 
],
[
          402.5,
         0.206 
],
[
            412,
         0.177 
],
[
          421.5,
         0.232 
],
[
            431,
         0.164 
],
[
            448,
         0.136 
],
[
          477.5,
         0.183 
] 
],
&quot;name&quot;: &quot;Points Against&quot;,
&quot;type&quot;: null,
&quot;marker&quot;: {
 &quot;radius&quot;:              3 
} 
},
{
 &quot;data&quot;: [
 [
           34.5,
             0 
],
[
           62.5,
             0 
],
[
           71.5,
             0 
],
[
           77.5,
             0 
],
[
             83,
         0.015 
],
[
             88,
         0.018 
],
[
             92,
         0.016 
],
[
             96,
         0.017 
],
[
           99.5,
             0 
],
[
          102.5,
         0.048 
],
[
            105,
             0 
],
[
            108,
          0.05 
],
[
          111.5,
         0.127 
],
[
          114.5,
         0.102 
],
[
            117,
         0.125 
],
[
          119.5,
         0.125 
],
[
            122,
         0.115 
],
[
            124,
         0.055 
],
[
          126.5,
         0.159 
],
[
            129,
         0.149 
],
[
            131,
         0.183 
],
[
          133.5,
         0.088 
],
[
            136,
         0.147 
],
[
            138,
          0.18 
],
[
            140,
         0.158 
],
[
            142,
         0.096 
],
[
            144,
         0.098 
],
[
            146,
         0.211 
],
[
          147.5,
         0.197 
],
[
            149,
         0.143 
],
[
            151,
         0.164 
],
[
            153,
         0.167 
],
[
            155,
         0.189 
],
[
            157,
         0.305 
],
[
            159,
         0.433 
],
[
          160.5,
         0.262 
],
[
            162,
         0.361 
],
[
            164,
         0.149 
],
[
          165.5,
         0.276 
],
[
            167,
         0.324 
],
[
            169,
         0.391 
],
[
          170.5,
         0.324 
],
[
            172,
         0.315 
],
[
          173.5,
         0.296 
],
[
            175,
           0.4 
],
[
            177,
          0.39 
],
[
            179,
         0.259 
],
[
            181,
         0.323 
],
[
          182.5,
         0.397 
],
[
            184,
         0.364 
],
[
          185.5,
         0.314 
],
[
            187,
         0.321 
],
[
          188.5,
         0.343 
],
[
            190,
         0.403 
],
[
            192,
         0.406 
],
[
          193.5,
         0.478 
],
[
            195,
         0.446 
],
[
          196.5,
         0.378 
],
[
            198,
         0.381 
],
[
          199.5,
         0.328 
],
[
            201,
         0.339 
],
[
            203,
         0.475 
],
[
            205,
          0.44 
],
[
            207,
         0.407 
],
[
          208.5,
         0.493 
],
[
          209.5,
         0.514 
],
[
            211,
         0.382 
],
[
          212.5,
         0.579 
],
[
          213.5,
         0.429 
],
[
            215,
         0.367 
],
[
            217,
         0.418 
],
[
            219,
         0.344 
],
[
          220.5,
           0.5 
],
[
            222,
         0.446 
],
[
            224,
         0.362 
],
[
          225.5,
         0.353 
],
[
          226.5,
         0.531 
],
[
            228,
         0.488 
],
[
          229.5,
         0.429 
],
[
            231,
         0.562 
],
[
            233,
         0.559 
],
[
            235,
         0.706 
],
[
          236.5,
         0.548 
],
[
            238,
         0.475 
],
[
            240,
         0.561 
],
[
          241.5,
         0.687 
],
[
            243,
         0.673 
],
[
          244.5,
         0.587 
],
[
            246,
         0.621 
],
[
            248,
         0.623 
],
[
            250,
         0.596 
],
[
            252,
          0.69 
],
[
            254,
         0.547 
],
[
            256,
         0.705 
],
[
          257.5,
         0.647 
],
[
            259,
         0.729 
],
[
            261,
         0.633 
],
[
            263,
         0.719 
],
[
            265,
         0.644 
],
[
          266.5,
         0.787 
],
[
            268,
         0.693 
],
[
          270.5,
         0.672 
],
[
            273,
         0.772 
],
[
            275,
           0.8 
],
[
          276.5,
         0.604 
],
[
            278,
         0.746 
],
[
            280,
         0.706 
],
[
            282,
          0.75 
],
[
          283.5,
         0.708 
],
[
            285,
         0.845 
],
[
            287,
           0.7 
],
[
            289,
         0.889 
],
[
            291,
         0.714 
],
[
          293.5,
         0.908 
],
[
          295.5,
         0.796 
],
[
            297,
          0.75 
],
[
          299.5,
         0.811 
],
[
            302,
         0.806 
],
[
          304.5,
         0.839 
],
[
            307,
         0.929 
],
[
          309.5,
         0.905 
],
[
            312,
         0.889 
],
[
          314.5,
         0.827 
],
[
          317.5,
         0.789 
],
[
            321,
         0.873 
],
[
          324.5,
         0.883 
],
[
          327.5,
         0.954 
],
[
          330.5,
         0.898 
],
[
            334,
         0.905 
],
[
          337.5,
         0.909 
],
[
          340.5,
         0.981 
],
[
          343.5,
             1 
],
[
            347,
         0.984 
],
[
            351,
         0.962 
],
[
            355,
         0.957 
],
[
            359,
         0.931 
],
[
            363,
          0.98 
],
[
            367,
          0.97 
],
[
          371.5,
          0.93 
],
[
          376.5,
             1 
],
[
            382,
         0.984 
],
[
          387.5,
         0.984 
],
[
            394,
         0.981 
],
[
          402.5,
         0.982 
],
[
            412,
             1 
],
[
          421.5,
         0.984 
],
[
            431,
             1 
],
[
            448,
             1 
],
[
          477.5,
             1 
] 
],
&quot;name&quot;: &quot;Points Scored&quot;,
&quot;type&quot;: null,
&quot;marker&quot;: {
 &quot;radius&quot;:              3 
} 
} 
],
&quot;xAxis&quot;: [
 {
 &quot;title&quot;: {
 &quot;text&quot;: &quot;Points&quot; 
},
&quot;min&quot;:              0,
&quot;max&quot;:            500,
&quot;tickInterval&quot;:            100 
} 
],
&quot;subtitle&quot;: {
 &quot;text&quot;: null 
},
&quot;legend&quot;: {
 &quot;verticalAlign&quot;: &quot;top&quot;,
&quot;align&quot;: &quot;right&quot;,
&quot;layout&quot;: &quot;vertical&quot;,
&quot;title&quot;: {
 &quot;text&quot;: &quot;Group&quot; 
} 
},
&quot;plotOptions&quot;: {
 &quot;series&quot;: {
 &quot;lineWidth&quot;:              2 
} 
},
&quot;id&quot;: &quot;chart1&quot;,
&quot;chart&quot;: {
 &quot;renderTo&quot;: &quot;chart1&quot; 
} 
});
        });
    })(jQuery);
&lt;/script&gt;



</description>
				<pubDate>Fri, 05 Sep 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/09/05/winpct/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/09/05/winpct/</guid>
			</item>
		
			<item>
				<title>Dodged bar charts, why not a line graph?</title>
				<description>&lt;p&gt;I often see graphs that are poorly implemented in that they do not achieve their goal.  One such type of graph that I see are dodged bar charts.  Here is an example of a dodged bar chart summarizing the number of all star players by team (focusing specifically on the AL central division) and year from the &lt;em&gt;Lahman&lt;/em&gt; r package:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(Lahman)
library(dplyr)
library(ggplot2)
library(RColorBrewer)

AllstarFull$selected &amp;lt;- 1

numAS &amp;lt;- AllstarFull  %&amp;gt;% 
  filter(yearID &amp;gt; 2006, lgID == &#39;AL&#39;, teamID %in% c(&#39;MIN&#39;, &#39;CLE&#39;, &#39;DET&#39;, &#39;CHA&#39;, &#39;KCA&#39;)) %&amp;gt;%
  group_by(teamID, yearID) %&amp;gt;%
  summarise(number = sum(selected))

b &amp;lt;- ggplot(numAS, aes(x = teamID, y = number, fill = factor(yearID))) + theme_bw()
b + geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) + 
  scale_fill_brewer(&quot;Year&quot;, palette = &quot;Dark2&quot;) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/bar.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note: If you are curious from the above graph, there appears to be two typos in the teamIDs, where CHA should be CHW (Chicago White Sox) and KCA should be KCR (Kansas City Royals).&lt;/p&gt;

&lt;p&gt;The plot above can be good for a few things, predominantly for comparison within a team. It is more difficult to compare between teams (although not impossible).  One way to possibly improve the plot would be to add the number either above each bar or inside of each bar.  This can be done in &lt;em&gt;ggplot2&lt;/em&gt; with the &lt;em&gt;geom_text&lt;/em&gt; function.  For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;b &amp;lt;- ggplot(numAS, aes(x = teamID, y = number, fill = factor(yearID))) + theme_bw()
b + geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) + 
  scale_fill_brewer(&quot;Year&quot;, palette = &quot;Dark2&quot;) + 
  geom_text(aes(label = number), position = position_dodge(width = 0.9), 
            vjust = 1.5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/bartext.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A better alternative to a dodged bar chart in my opinion would be a simple line graph.  The line graph simplifies the graph to only include one variable on the x-axis and uses colors or shapes to differentiate the teams. See below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;l &amp;lt;- ggplot(numAS, aes(x = yearID, y = number, color = teamID, shape = teamID))
l + geom_point(size = 4) + geom_line(size = 1) +
  scale_y_continuous(limits = c(0, 7), expand = c(0,0)) + 
  scale_color_brewer(&quot;Team&quot;, palette = &quot;Dark2&quot;) + scale_shape_discrete(&quot;Team&quot;) + 
  xlab(&quot;Year&quot;) + theme_bw()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/line.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This presentation makes it much easier to compare teams within a single year and also see how the teams have changed over time. The ability to see differences also increases as the variability in the variable increases. In my opinion this is a much simpler graphic and usually is a better option to serve the purpose for the graphic. As always though, the best graphic is one that conveys the message in the simplest, easiest to understand form. You could improve this by making it interactive with &lt;em&gt;rCharts&lt;/em&gt;.  See my post on &lt;em&gt;rCharts&lt;/em&gt; &lt;a href=&quot;/2014/02/15/rcharts/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;/2014/03/03/rChartsslidy/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Tue, 05 Aug 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/08/05/trendgraphics/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/08/05/trendgraphics/</guid>
			</item>
		
			<item>
				<title>Format Markdown Documents in R</title>
				<description>&lt;p&gt;Have you ever used a markdown file to create an html file?  Have you ever wanted to quickly format the subsequent html file to add some color or other aspects?  If your answer is yes to both of those questions, this package may be of interest to you.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;&lt;a href=&quot;https://github.com/lebebr01/highlightHTML&quot;&gt;highlightHTML&lt;/a&gt;&lt;/strong&gt; package aims to develop a flexible approach to add formatting to an html document by injecting CSS into the file.  To do this, tags are created within the markdown document telling the R routine where to look for these tags.  If you are familiar with the Twitterverse, this package will be equally comfortable.  The tags take the form of the hashtags on Twitter.  As an example, #bgblue, would be a command to change the background to blue.&lt;/p&gt;

&lt;p&gt;The next thing needed by the package is to tell how much of the word, sentence, or header that should be affected by the tag.  To do this, add braces before the tag and include all the content you want to be affected by the tag.  For example, {#bggold this example will have a blue background}.&lt;/p&gt;

&lt;p&gt;Once any tags you want to include are in the markdown document, then the document can be converted into a html file using programs such as &lt;em&gt;knitr&lt;/em&gt;, &lt;em&gt;pandoc&lt;/em&gt;, the RStudio &quot;knit HTML&quot; button (or any others).  Once the resulting html file is compiled, then run the html file through the &lt;strong&gt;highlightHTML&lt;/strong&gt; package and the html file is searched for the tags, the tags are changed to CSS ids, and by default the CSS tags will be inserted automatically back into the document.&lt;/p&gt;

&lt;h3&gt;Minimal Example&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;A markdown document that looks like the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;markdown&quot;&gt;# Test of {#colgold highlightHTML} package

Can highlight {#bgblack multiple words}.

Even tables:

| Color Name | Number     |  
|------------|------------|  
| Blue       | 5  #bgblue |  
| Green      | 35         |  
| Orange     | 100        |  
| Red        | 200 #bgred |  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You would then convert the markdown above into a html file (I hit the knit HTML button in RStudio for this file), then run the following commands in R (assuming the highlightHTML package is not installed):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(devtools)
install_github(repo = &quot;highlightHTML&quot;, username = &quot;lebebr01&quot;)
library(highlightHTML)

tags &amp;lt;- c(&quot;#bgred {background-color: red;}&quot;, &quot;#bgblue {background-color: blue;}&quot;,
          &quot;#colgold {color: gold;}&quot;, &quot;#bgblack {background-color: black; color: white;}&quot;)
highlightHTML(input = &quot;path/to/infile.html&quot;, output = &quot;path/to/outfile.html&quot;, 
              updateCSS = TRUE, tags = tags, browse = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command will process the html file, look for tags, change the tags to CSS ids, inject the CSS into the document, and lastly open the output file in the browser to see how it looks.  The example above would look like the following after the above commands:
&lt;img src=&quot;http://educate-r.org/figs/mwe.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can also go to this link to see the post-processed file: &lt;a href=&quot;/mwe.html&quot;&gt;educate-r.org/mwe.html&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Upcoming Features&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;Currently the package assumes that you know CSS and can supply your own tags.  In the future I&#39;d like to relax this and allow for some basic tags that work without needing to supply the CSS.  I&#39;m hoping to allow background color and text color changes to be made without needing to specify the CSS.  For example, when specifying #bgblue in the markdown file, the R program knows that you want the background color (bg) to be blue.&lt;/p&gt;

&lt;p&gt;Try it out and let me know of new features or bugs as you work through the package.&lt;/p&gt;
</description>
				<pubDate>Wed, 30 Jul 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/07/30/highlightHTML/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/07/30/highlightHTML/</guid>
			</item>
		
			<item>
				<title>R gui Revisited</title>
				<description>&lt;p&gt;A couple months ago I wrote about switching my class from using SPSS to one that uses R with a gui frontend (&lt;a href=&quot;http://educate-r.org/2014/02/03/Rgui/&quot;&gt;original post&lt;/a&gt;).  Since the semester has wrapped up, below are my thoughts on how the course went with respect to the students using R.&lt;/p&gt;

&lt;h4&gt;Things that went well&lt;/h4&gt;

&lt;hr /&gt;

&lt;p&gt;Many students by the end were starting to understand the power of R (even through a gui structure).  Most were able to create new variables, run statistical analyses, produce basic graphs or figures, and even understand a few basic commands. They also enjoyed that the language and program were free and they could bring their laptops to class when we were going to talk about doing something new in R.&lt;/p&gt;

&lt;p&gt;I also did not hear any stories of a gui system crashing (which was one complaint of &lt;em&gt;Deducer&lt;/em&gt; in the comments of my last post).  I had students using either &lt;em&gt;Deducer&lt;/em&gt; or &lt;em&gt;Rcmdr&lt;/em&gt;, but whenever possible steered them toward &lt;em&gt;Deducer&lt;/em&gt; as it is a bit more user friendly (in my opinion) and uses &lt;em&gt;ggplot2&lt;/em&gt; by default for graphics.  Although &lt;em&gt;Deducer&lt;/em&gt; did crash on me once while demonstrating something during class, I did not hear any students complain about it.&lt;/p&gt;

&lt;p&gt;During the last two weeks of the course when more assignments surrounding basic inferential methods were due, students were becoming much more confident and better able to navigate the R gui menus.  I do also think that the students did appreciate the simpleness of the R output, only giving you what you ask for (as compared to SPSS that gives you extremely more than you ask for). One part of any gui system is to figure out the menu structure and understand the basic language of the menu.  Once I was able to point students to the correct menus, give them correct names for statistical procedures, and also point out specific R terminology they were much more comfortable doing things on their own (and even on occasion trying new things on their own).&lt;/p&gt;

&lt;h4&gt;Things that went poorly&lt;/h4&gt;

&lt;hr /&gt;

&lt;p&gt;Using both &lt;em&gt;Deducer&lt;/em&gt; and &lt;em&gt;Rcmdr&lt;/em&gt; in the class.  I did not want to do this initially, but was forced to do it as I was unsure initially why some students were getting an error (it is based on the Java version installed).  I should have spent more time trying to transition students to &lt;em&gt;Deducer&lt;/em&gt; after figuring out the error, however did not want to have them learn a new system after starting to learn &lt;em&gt;Rcmdr&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Another sticky spot was that I did not have students learn &lt;em&gt;Markdown&lt;/em&gt;, therefore students were copying and pasting output into Word. If anyone has tried this in the past, it usually does not format the best.  In the future (definitely for a PhD level course) I would have students learn &lt;em&gt;Markdown&lt;/em&gt; as it would likely not take more than an hour.&lt;/p&gt;

&lt;p&gt;Students using &lt;em&gt;Rcmdr&lt;/em&gt; had difficulty created dichotomous variables from a continuous variable.  With &lt;em&gt;Rcmdr&lt;/em&gt;, one needs to know some basic R commands (like &lt;em&gt;ifelse&lt;/em&gt;) in order to create dichotomous variables.  This is not something that I spent much time going over in class and was a definite stumbling block for many students.&lt;/p&gt;

&lt;p&gt;An unfortunate aspect of any course where students need to learn software (or just any type of material in general) is that some students do not feel the software is something they are going to use down the road.  As a result, a handful of students seemed to be a bit more obstinate regarding the use of R (and my guess would have been a similar reaction to using SPSS).&lt;/p&gt;

&lt;p&gt;Lastly, I did not have assignments that focused specifically on learning R.  If I ever teach a course of this level again (which may not occur at my new job at the University of Iowa) I would definitely have more regular small assignments to accomplish more data manipulation tasks, such as creating a new variable, turn a variable into a factor, etc.&lt;/p&gt;

&lt;h4&gt;Summary&lt;/h4&gt;

&lt;hr /&gt;

&lt;p&gt;In general I was pleased with using R and more specifically using a R gui for the the course.  The scope of the class was not to teach students a statistical language and for many of these students this was likely their last research/statistics course. This gave me one shot to try to get them familiar enough with the program to be an option for them in the future.  I do feel that the students became familiar enough with R during the course to be able to use it for basic data manipulation and analysis in the future, but are still tied to the gui system.&lt;/p&gt;

&lt;p&gt;With that being said, if I ever teach a similar course in the future, I would likely create a shiny app that allows students to interact in the browser instead of using the R gui. The scope of the course is focused more on interpretation of the output rather than learning the statistical package to get the output, so the shiny app would work well (I&#39;m imagining a Tinkerplots-esque look and feel). I would also recommend for anyone who has students and a course at a similar level and you choose to use a gui system for R, to use &lt;em&gt;Deducer&lt;/em&gt;.  Once the initial setup bottlenecks are worked out it is much easier for the students to learn and use (and is more similar to SPSS if they use that program in the future).&lt;/p&gt;
</description>
				<pubDate>Tue, 27 May 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/05/27/rguirevisit/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/05/27/rguirevisit/</guid>
			</item>
		
			<item>
				<title>AERA Preview</title>
				<description>&lt;p&gt;The American Educational Research Association (AERA) annual conference is this weekend in Philadelphia.  I was lucky to have a paper accepted into the conference.  I am presenting a meta analysis that I have been working on for the past two years or so titled: Model misspecification and assumption violations with the linear mixed model: A meta analysis.&lt;/p&gt;

&lt;p&gt;In this paper, I have compiled numerous monte carlo studies perform a quantitative synthesis of the literature.  I have focused primarily on longitudinal linear mixed models as that was what my dissertation topic, and practically speaking, I already had many monte carlo studies in hand making the task a bit simpler.&lt;/p&gt;

&lt;p&gt;Here is a sneak peak of some of the results from my paper in the form of an interactive chart using the &lt;em&gt;rChart&lt;/em&gt; package to get started.  Here is my r code to generate the initial chart:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rCharts)
h1 &amp;lt;- hPlot(x = &quot;fitSerCor2&quot;, y = &quot;avgt1e&quot;, group = &quot;missRE&quot;, data = intmean)
h1$yAxis(title = list(text = &quot;Empirical Type I Error Rate&quot;), min = 0.00, max = 0.2, tickInterval = 0.05)
h1$xAxis(title = list(text = &quot;Fitted Serial Correlation Structure&quot;),
         categories = c(&quot;Ind&quot;, &quot;AR1&quot;, &quot;MA1&quot;, &quot;MA2&quot;, &quot;ARMA&quot;))
h1$legend(verticalAlign = &quot;top&quot;, align = &quot;right&quot;, layout = &quot;vertical&quot;, title = list(text = &quot;Miss RE&quot;))
h1$print(&#39;chart1&#39;, include_assets = TRUE, cdn = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As in one of my prior posts about &lt;em&gt;rCharts&lt;/em&gt; I manually added a few features to the Javascript manually.  I find that easier than bundling lists upon lists to achieve the desired result.  Below is the final image:&lt;/p&gt;

&lt;script type=&#39;text/javascript&#39; src=http://code.jquery.com/jquery-1.9.1.min.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/highcharts.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/highcharts-more.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/modules/exporting.js&gt;&lt;/script&gt;


&lt;p&gt;
 &lt;style&gt;
  .rChart {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
    height: 600px;
    font-size: 200%;
  }&lt;br/&gt;
  &lt;/style&gt;&lt;/p&gt;

&lt;div id = &#39;chart1&#39; class = &#39;rChart highcharts&#39;&gt;&lt;/div&gt;


&lt;script type=&#39;text/javascript&#39;&gt;
    (function($){
        $(function () {
            var chart = new Highcharts.Chart({
 &quot;dom&quot;: &quot;chart1&quot;,
&quot;width&quot;:            800,
&quot;height&quot;:            400,
&quot;credits&quot;: {
 &quot;href&quot;: null,
&quot;text&quot;: null 
},
&quot;exporting&quot;: {
 &quot;enabled&quot;: false 
},
&quot;title&quot;: {
 &quot;text&quot;: null 
},
&quot;yAxis&quot;: [
 {
 &quot;title&quot;: {
 &quot;text&quot;: &quot;Empirical Type I Error Rate&quot;,
   style: {
   fontWeight: &#39;bold&#39;,
   fontSize: &#39;20px&#39;
   }
},
labels: {
  style: {
   fontSize: &#39;18px&#39;
  }
 },
&quot;min&quot;:              0,
&quot;max&quot;:            0.2,
&quot;tickInterval&quot;:           0.05 
} 
],
&quot;series&quot;: [
 {
 &quot;data&quot;: [
 [
 &quot;Ind&quot;,
0.0519
],
 [
 &quot;AR1&quot;,
0.0635
],
[
 &quot;MA1&quot;,
0.0639
],
[
 &quot;MA2&quot;,
0.0665
], 
[
 &quot;ARMA&quot;,
0.0656
],
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#e41a1c&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#e41a1c&quot;,
&quot;name&quot;: &quot;0&quot;,
&quot;type&quot;: null,
&quot;marker&quot;: {
 &quot;radius&quot;:              6
} 
},
{
 &quot;data&quot;: [
 [
 &quot;Ind&quot;,
0.1837
],
 [
 &quot;AR1&quot;,
0.0864
],
[
 &quot;MA1&quot;,
0.1155
],
[
 &quot;MA2&quot;,
0.0999
], 
[
 &quot;ARMA&quot;,
0.0896
],
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#377eb8&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#377eb8&quot;,
&quot;name&quot;: &quot;1&quot;,
&quot;type&quot;: null,
&quot;marker&quot;: {
 &quot;radius&quot;:              6
} 
} 
],
&quot;xAxis&quot;: [
 {
 &quot;title&quot;: {
 &quot;text&quot;: &quot;Fitted Serial Correlation Structure&quot;,
 style:{
   fontWeight: &#39;bold&#39;,
   fontSize: &#39;20px&#39;
 }
},
labels: {
 style: {
  fontSize: &#39;18px&#39;,
  fontWeight: &#39;bold&#39;
 }
},
&quot;categories&quot;: [ &quot;Ind&quot;, &quot;AR1&quot;, &quot;MA1&quot;, &quot;MA2&quot;, &quot;ARMA&quot; ] 
} 
],
&quot;subtitle&quot;: {
 &quot;text&quot;: null 
},
&quot;legend&quot;: {
 &quot;verticalAlign&quot;: &quot;top&quot;,
&quot;align&quot;: &quot;right&quot;,
&quot;layout&quot;: &quot;vertical&quot;,
symbolWidth: 40,
&quot;title&quot;: {
 &quot;text&quot;: &quot;Miss RE&quot; 
} 
},
&quot;plotOptions&quot;: {
 &quot;series&quot;: {
 &quot;lineWidth&quot;:              4 
} 
},
&quot;id&quot;: &quot;chart1&quot;,
&quot;chart&quot;: {
 &quot;renderTo&quot;: &quot;chart1&quot;,
  zoomType: &quot;y&quot;,
   &quot;style&quot;: {
 fontSize: &quot;24px&quot;
 },
 resetZoomButton: {
  position: {
   align: &#39;left&#39;
  }
 }
} 
});
        });
    })(jQuery);
&lt;/script&gt;


&lt;p&gt;If anyone is attending AERA this year and wants to listen to my presentation as well as others dealing with Methodological Considerations in Modeling Latent Growth (the title of the session) stop by the Convention Center on Sunday, April 6th from 4:05 to 5:35 pm in room 117.  Even if you do not want to hear about modeling latent growth, but would rather talk about r, perhaps we can meetup somewhere else.&lt;/p&gt;
</description>
				<pubDate>Wed, 02 Apr 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/04/02/aerapreview/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/04/02/aerapreview/</guid>
			</item>
		
			<item>
				<title>Evolution of Code</title>
				<description>&lt;p&gt;Recently while scraping some data from the college football data warehouse site, I started to realize the evolution of my code.  To preface this, I am definitely not a trained programmer, just a self taught junky who enjoys doing it when I have time.  I&#39;ve slowly evolved my programming skills from simply statistics languages like r or SPSS, to some other languages like LaTeX, HTML, CSS, Javascript, and I&#39;ve started to work through some python.&lt;/p&gt;

&lt;p&gt;Now back to my realization.  As I mentioned, I was scraping some data from &lt;a href=&quot;http://www.cfbdatawarehouse.com/&quot;&gt;CFB Data Warehouse&lt;/a&gt; for a project that I&#39;m working on with a colleague and was adapting some code that was written about 3 years ago.  The problem was that my old code was broken.  The original code was about 100 lines of code just to select the correct table and format it.  Here is a chunk of the original code to select the correct table.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;  ##Identifying correct tables
    tb &amp;lt;- vector(&quot;list&quot;, length(tableNodes))
      for(i in 1:length(tableNodes)){
        tb[[i]] &amp;lt;- readHTMLTable(tableNodes[[i]])
      }

  ##Tables that are the correct length
    tabNum &amp;lt;- matrix(nrow=length(tableNodes), ncol=2)
    tabNum[,1] &amp;lt;- sapply(tb, length)
    tabNum[,2] &amp;lt;- 1:length(tableNodes)

   Num &amp;lt;- subset(tabNum, tabNum[,1] == 7)[,2]

  ##Selecting and combining tables
if(length(Num) == 5){
   tb1 &amp;lt;- tb[[Num[3]]]
   tb1$Other &amp;lt;- 0
   tb2 &amp;lt;- tb[[Num[5]]]
   tb2$Other &amp;lt;- 1
   tab &amp;lt;- rbind(tb1, tb2)
 } else { 
  if(length(Num) ==3){
   tab &amp;lt;- tb[[Num[3]]]
   tab$Other &amp;lt;- 1
 } else {
  tab &amp;lt;- matrix(NA, ncol= 8, nrow=1)  
 }
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code was looped over many different pages and was run once for every page.  Essentially the code is complicated and inconsistent, but at the time 3 years ago the code ran and that was enough for me.  Extract the data from the website no matter how much code was needed to do the work.  This was back in an era when I was just becoming familiar with much or &lt;em&gt;R&lt;/em&gt;, the &lt;em&gt;XML&lt;/em&gt; package, and attempting to scrape data from a messy/complicated site.&lt;/p&gt;

&lt;p&gt;My new code to extract the tables looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# extracting tables
  tabs &amp;lt;- lapply(seq(3, length(Nodes), 1), function(x) 
    readHTMLTable(Nodes[[x]], stringsAsFactors = FALSE))

  # Combine tables
  bowl &amp;lt;- do.call(&quot;rbind&quot;, tabs)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Much cleaner, simpler, more consistent, and quite possibly quicker.  The ability to focus on speed, readability, and consistency is something that comes later after one becomes more comfortable with the language.  I have been focusing on this for awhile, but these stark differences and ease I was able to adapt my old code especially struck me this time.  I haven&#39;t decided if this evolution for me is &lt;em&gt;mastery&lt;/em&gt; or &lt;em&gt;expert&lt;/em&gt; status of the r language, but I now feel I have progressed to a point where I feel confident and am able to shift my focus from having code that works, to code that is now clean, consistent, and readable.&lt;/p&gt;

&lt;p&gt;Has anyone else had similar epiphanies with their code?&lt;/p&gt;

&lt;p&gt;Lastly, if you want to see the raw code, go to the github page: &lt;a href=&quot;https://github.com/lebebr01/cfbFootball&quot;&gt;https://github.com/lebebr01/cfbFootball&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Thu, 27 Mar 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/03/27/evolvecode/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/03/27/evolvecode/</guid>
			</item>
		
			<item>
				<title>Update to highlightHTML package</title>
				<description>&lt;p&gt;I&#39;ve added a new functionality to my &lt;em&gt;highlightHTML&lt;/em&gt; package.  This package post-processes HTML files and injects CSS and adds tags to create some further customization (for example highlight cells of a HTML table).  This is most useful when writing a document using markdown and converting it into a HTML document using a tool like knitr, slidify, or even pandoc.&lt;/p&gt;

&lt;p&gt;Up to now, my package only worked with tables, see my old post that talks about this if you are interested: &lt;a href=&quot;http://educate-r.org/2013/11/01/CondFormatMarkdown/&quot;&gt;highlight tables&lt;/a&gt;.  My update adds a similar functionality to text itself by including span tags in the document.&lt;/p&gt;

&lt;p&gt;The following code will install the package with the new feature from github:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(devtools)
install_github(repo = &quot;highlightHTML&quot;, username = &quot;lebebr01&quot;, ref = &quot;testing&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the package is installed, the new function is called &lt;strong&gt;highlightHTMLtext&lt;/strong&gt;. This function takes a HTML file as the input and post processes the file to add span tags to format text according to the CSS calls specified by the user.  The function looks for {#id text} to add the span tags.  The braces are used to define the text range that will use the id and the #id is the CSS id itself.&lt;/p&gt;

&lt;p&gt;Here is an example using the HTML file that comes with the package and which can also be found in the help file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(highlightHTML)
file &amp;lt;- system.file(&#39;examples&#39;, package = &#39;highlightHTML&#39;)
file1 &amp;lt;- paste(file, &quot;bgtext.html&quot;, sep = &quot;/&quot;)

# Change background color and text color with CSS
tags &amp;lt;- c(&quot;#bgblack {background-color: black; color: white;}&quot;,
  &quot;#bgblue {background-color: #0000FF; color: white;}&quot;)

# Post-process HTML file
highlightHTMLtext(input = file1, output = NULL, updateCSS = TRUE,
  tags = tags, browse = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you run the above command, the file should open in your browser to see the result of the new HTML file.  The result should have boxes of color in specific areas that we indicated by the {#id text} syntax in the raw markdown and HTML file.&lt;/p&gt;

&lt;p&gt;My next step is to develop a master function to wrap these other functions so only one call would be needed to format text and tables.  Let me know of any issues by going to the github page: &lt;a href=&quot;https://github.com/lebebr01/highlightHTML&quot;&gt;report bugs&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt;Before and After HTML&lt;/h3&gt;

&lt;p&gt;Here is what the body of the HTML file looks like before running the function:
```html
&lt;body&gt;&lt;/p&gt;

&lt;h1&gt;Test of Text&lt;/h1&gt;


&lt;p&gt;Testing the ability to change the {#bgblue color} of the text.&lt;/p&gt;


&lt;p&gt;Can also do {#bgblack multiple words of text}&lt;/p&gt;


&lt;p&gt;{#bgblack Even entire paragraphs that you want to really stand out from the rest of the document.  More than color could also be changed, anything alterable by CSS.  Test out the function and get creative with the CSS}&lt;/p&gt;


&lt;p&gt;&lt;/body&gt;
```&lt;/p&gt;

&lt;p&gt;This is what the HTML document looks like after running the function:
```html
&lt;body&gt;&lt;/p&gt;

&lt;h1&gt;Test of Text&lt;/h1&gt;


&lt;p&gt;Testing the ability to change the &lt;span id=&#39;bgblue&#39;&gt; color&lt;/span&gt; of the text.&lt;/p&gt;


&lt;p&gt;Can also do &lt;span id=&#39;bgblack&#39;&gt; multiple words of text&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span id=&#39;bgblack&#39;&gt; Even entire paragraphs that you want to really stand out from the rest of the document.  More than color could also be changed, anything alterable by CSS.  Test out the function and get creative with the CSS&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;/body&gt;
```&lt;/p&gt;

&lt;p&gt;The braces identify the location of the span tags and the custom CSS id tag to format the text.&lt;/p&gt;
</description>
				<pubDate>Fri, 14 Mar 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/03/14/htmltext/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/03/14/htmltext/</guid>
			</item>
		
	</channel>
</rss>
